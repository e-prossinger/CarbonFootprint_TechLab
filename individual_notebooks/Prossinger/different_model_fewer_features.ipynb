{"cells":[{"cell_type":"markdown","metadata":{},"source":["# different model and fewer features"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T12:48:09.448061Z","iopub.status.busy":"2024-07-24T12:48:09.447651Z","iopub.status.idle":"2024-07-24T12:48:09.527686Z","shell.execute_reply":"2024-07-24T12:48:09.526431Z","shell.execute_reply.started":"2024-07-24T12:48:09.448033Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Body_Type</th>\n","      <th>Sex</th>\n","      <th>Diet</th>\n","      <th>How_Often_Shower</th>\n","      <th>Heating_Energy_Source</th>\n","      <th>Transport</th>\n","      <th>Vehicle_Type</th>\n","      <th>Social_Activity</th>\n","      <th>Monthly_Grocery_Bill</th>\n","      <th>Frequency_of_Traveling_by_Air</th>\n","      <th>Vehicle_Monthly_Distance_Km</th>\n","      <th>Waste_Bag_Size</th>\n","      <th>Waste_Bag_Weekly_Count</th>\n","      <th>How_Long_TV_PC_Daily_Hour</th>\n","      <th>How_Many_New_Clothes_Monthly</th>\n","      <th>How_Long_Internet_Daily_Hour</th>\n","      <th>Energy_efficiency</th>\n","      <th>Recycling</th>\n","      <th>Cooking_With</th>\n","      <th>CarbonEmission</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>overweight</td>\n","      <td>female</td>\n","      <td>pescatarian</td>\n","      <td>daily</td>\n","      <td>coal</td>\n","      <td>public</td>\n","      <td>NaN</td>\n","      <td>often</td>\n","      <td>230</td>\n","      <td>frequently</td>\n","      <td>210</td>\n","      <td>large</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>26</td>\n","      <td>1</td>\n","      <td>No</td>\n","      <td>['Metal']</td>\n","      <td>['Stove', 'Oven']</td>\n","      <td>2238</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>obese</td>\n","      <td>female</td>\n","      <td>vegetarian</td>\n","      <td>less frequently</td>\n","      <td>natural gas</td>\n","      <td>walk/bicycle</td>\n","      <td>NaN</td>\n","      <td>often</td>\n","      <td>114</td>\n","      <td>rarely</td>\n","      <td>9</td>\n","      <td>extra large</td>\n","      <td>3</td>\n","      <td>9</td>\n","      <td>38</td>\n","      <td>5</td>\n","      <td>No</td>\n","      <td>['Metal']</td>\n","      <td>['Stove', 'Microwave']</td>\n","      <td>1892</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>overweight</td>\n","      <td>male</td>\n","      <td>omnivore</td>\n","      <td>more frequently</td>\n","      <td>wood</td>\n","      <td>private</td>\n","      <td>petrol</td>\n","      <td>never</td>\n","      <td>138</td>\n","      <td>never</td>\n","      <td>2472</td>\n","      <td>small</td>\n","      <td>1</td>\n","      <td>14</td>\n","      <td>47</td>\n","      <td>6</td>\n","      <td>Sometimes</td>\n","      <td>['Metal']</td>\n","      <td>['Oven', 'Microwave']</td>\n","      <td>2595</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>overweight</td>\n","      <td>male</td>\n","      <td>omnivore</td>\n","      <td>twice a day</td>\n","      <td>wood</td>\n","      <td>walk/bicycle</td>\n","      <td>NaN</td>\n","      <td>sometimes</td>\n","      <td>157</td>\n","      <td>rarely</td>\n","      <td>74</td>\n","      <td>medium</td>\n","      <td>3</td>\n","      <td>20</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>Sometimes</td>\n","      <td>['Paper', 'Plastic', 'Glass', 'Metal']</td>\n","      <td>['Microwave', 'Grill', 'Airfryer']</td>\n","      <td>1074</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>obese</td>\n","      <td>female</td>\n","      <td>vegetarian</td>\n","      <td>daily</td>\n","      <td>coal</td>\n","      <td>private</td>\n","      <td>diesel</td>\n","      <td>often</td>\n","      <td>266</td>\n","      <td>very frequently</td>\n","      <td>8457</td>\n","      <td>large</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>Yes</td>\n","      <td>['Paper']</td>\n","      <td>['Oven']</td>\n","      <td>4743</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Body_Type     Sex         Diet How_Often_Shower Heating_Energy_Source  \\\n","0  overweight  female  pescatarian            daily                  coal   \n","1       obese  female   vegetarian  less frequently           natural gas   \n","2  overweight    male     omnivore  more frequently                  wood   \n","3  overweight    male     omnivore      twice a day                  wood   \n","4       obese  female   vegetarian            daily                  coal   \n","\n","      Transport Vehicle_Type Social_Activity  Monthly_Grocery_Bill  \\\n","0        public          NaN           often                   230   \n","1  walk/bicycle          NaN           often                   114   \n","2       private       petrol           never                   138   \n","3  walk/bicycle          NaN       sometimes                   157   \n","4       private       diesel           often                   266   \n","\n","  Frequency_of_Traveling_by_Air  Vehicle_Monthly_Distance_Km Waste_Bag_Size  \\\n","0                    frequently                          210          large   \n","1                        rarely                            9    extra large   \n","2                         never                         2472          small   \n","3                        rarely                           74         medium   \n","4               very frequently                         8457          large   \n","\n","   Waste_Bag_Weekly_Count  How_Long_TV_PC_Daily_Hour  \\\n","0                       4                          7   \n","1                       3                          9   \n","2                       1                         14   \n","3                       3                         20   \n","4                       1                          3   \n","\n","   How_Many_New_Clothes_Monthly  How_Long_Internet_Daily_Hour  \\\n","0                            26                             1   \n","1                            38                             5   \n","2                            47                             6   \n","3                             5                             7   \n","4                             5                             6   \n","\n","  Energy_efficiency                               Recycling  \\\n","0                No                               ['Metal']   \n","1                No                               ['Metal']   \n","2         Sometimes                               ['Metal']   \n","3         Sometimes  ['Paper', 'Plastic', 'Glass', 'Metal']   \n","4               Yes                               ['Paper']   \n","\n","                         Cooking_With  CarbonEmission  \n","0                   ['Stove', 'Oven']            2238  \n","1              ['Stove', 'Microwave']            1892  \n","2               ['Oven', 'Microwave']            2595  \n","3  ['Microwave', 'Grill', 'Airfryer']            1074  \n","4                            ['Oven']            4743  "]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split \n","from sklearn.linear_model import LinearRegression\n","from lightgbm import LGBMRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import RepeatedKFold\n","\n","\n","df=pd.read_csv('Carbon_Emission.csv',sep=\";\")\n","\n","#df = pd.read_csv('/kaggle/input/individual-carbon-footprint-calculation/Carbon Emission.csv')\n","#data can be found at https://www.kaggle.com/datasets/dumanmesut/individual-carbon-footprint-calculation/data\n","\n","\n","# change display settings to show all columns\n","pd.set_option('display.max_columns', None)\n","\n","\n","#rename\n","# rename columns: replace spaces with underscores\n","df.columns = df.columns.str.replace(' ', '_')\n","\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# **variables \"Transport\" and \"Vehicle Type\"**"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T12:01:14.398271Z","iopub.status.busy":"2024-07-24T12:01:14.397913Z","iopub.status.idle":"2024-07-24T12:01:14.418457Z","shell.execute_reply":"2024-07-24T12:01:14.417292Z","shell.execute_reply.started":"2024-07-24T12:01:14.398238Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Transport</th>\n","      <th>Vehicle_Type</th>\n","      <th>Transport_Vehicle_Type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>public</td>\n","      <td>NaN</td>\n","      <td>public</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>walk/bicycle</td>\n","      <td>NaN</td>\n","      <td>walk/bicycle</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>private</td>\n","      <td>petrol</td>\n","      <td>petrol</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>walk/bicycle</td>\n","      <td>NaN</td>\n","      <td>walk/bicycle</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>private</td>\n","      <td>diesel</td>\n","      <td>diesel</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Transport Vehicle_Type Transport_Vehicle_Type\n","0        public          NaN                 public\n","1  walk/bicycle          NaN           walk/bicycle\n","2       private       petrol                 petrol\n","3  walk/bicycle          NaN           walk/bicycle\n","4       private       diesel                 diesel"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["##create new column \"Transport Vehicle Type\" \n","df[\"Transport_Vehicle_Type\"]=df[\"Vehicle_Type\"] #create a new column\n","df.loc[df[\"Transport_Vehicle_Type\"].isna(), \"Transport_Vehicle_Type\"] = df[\"Transport\"] # Werte aus 'Transport' übernehmen, wenn 'Vehicle Type' NaN ist\n","\n","\n","##veranschaulichen der neuen Spalten und ihrer Werte\n","df[[\"Transport\",\"Vehicle_Type\",\"Transport_Vehicle_Type\"]].head()"]},{"cell_type":"markdown","metadata":{},"source":["# **Encoding & Scaling - ColumnTransformer**"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T12:01:14.519665Z","iopub.status.busy":"2024-07-24T12:01:14.519353Z","iopub.status.idle":"2024-07-24T12:01:14.586778Z","shell.execute_reply":"2024-07-24T12:01:14.584900Z","shell.execute_reply.started":"2024-07-24T12:01:14.519639Z"},"trusted":true},"outputs":[],"source":["\n","\n","\n","variables_quantitative =[\"Vehicle_Monthly_Distance_Km\", \"How_Many_New_Clothes_Monthly\",\"Waste_Bag_Weekly_Count\"]\n","variables_for_one_hot_encoded=['Frequency_of_Traveling_by_Air','Body_Type','Transport_Vehicle_Type']\n","\n","\n","X = df[variables_quantitative + variables_for_one_hot_encoded]  \n","\n","###########################################\n","\n","cf = ColumnTransformer(\n","    [(col, OneHotEncoder(drop=\"first\"), [col]) for col in variables_for_one_hot_encoded] +\n","    [(col, MinMaxScaler(), [col]) for col in variables_quantitative],  \n","    remainder=\"passthrough\")\n","\n","cf.fit(X)\n","X_transformed = cf.transform(X) # Data after scaling\n"," "]},{"cell_type":"markdown","metadata":{},"source":["#  Regression"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.status.busy":"2024-07-24T12:01:14.590532Z","iopub.status.idle":"2024-07-24T12:01:14.590991Z","shell.execute_reply":"2024-07-24T12:01:14.590810Z","shell.execute_reply.started":"2024-07-24T12:01:14.590791Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2265.216533\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2262.754800\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2276.686933\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2271.930933\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2272.091200\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2274.337600\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2272.303600\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2257.856800\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2262.882800\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2274.376400\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2267.681867\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2271.648133\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2269.852267\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2271.121600\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2259.086000\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2276.529333\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2276.721200\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2273.253600\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2265.132800\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2261.481600\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2269.637867\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2273.143733\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2263.423200\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2270.384400\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2262.734000\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2281.212000\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2271.624267\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2261.018933\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2262.502533\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2268.755067\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2273.690933\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2271.640667\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2276.313733\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2267.145733\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2260.074667\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2273.055067\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2265.385733\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2277.644800\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2264.096667\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 337\n","[LightGBM] [Info] Number of data points in the train set: 7500, number of used features: 15\n","[LightGBM] [Info] Start training from score 2269.462000\n","average R-squared (from train-set): 0.908\n","average R-squared (from test-set): 0.874\n"]}],"source":["\n","y = df[\"CarbonEmission\"]\n","\n","############################################\n","\n","kf = RepeatedKFold(n_splits = 4, n_repeats = 10)\n","\n","X_transformed = pd.DataFrame(X_transformed)\n","train_scores = []\n","test_scores = []\n","\n","for train_index, test_index in kf.split(X):\n","    X_train = X_transformed.loc[train_index]  #train_test_split muss man jetzt nicht mehr nehmen\n","    y_train = y.loc[train_index]\n","    X_test  = X_transformed.loc[test_index]\n","    y_test  = y.loc[test_index]\n","    \n","    model = LGBMRegressor()\n","    model.fit(X_train, y_train)\n","\n","   ##Evaluating the Model  ######################################################\n","    # Predict the target variable for the training and test sets\n","    y_train_pred = model.predict(X_train)\n","    y_test_pred = model.predict(X_test)\n","\n","\n","    train_scores.append(r2_score(y_train, y_train_pred))\n","    test_scores.append(r2_score(y_test, y_test_pred))\n","    \n","print(f\"average R-squared (from train-set): {np.mean(train_scores):.3f}\") #sollte auch train und nicht nur test-score ausgeben lassen damit overfitting überprüfen kann\n","print(f\"average R-squared (from test-set): {np.mean(test_scores):.3f}\")  \n","\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4442032,"sourceId":7625051,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
